{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = 'Dataset1.0/images'\n",
    "\n",
    "# 获取文件夹中的所有文件名\n",
    "file_names = os.listdir(folder_path)\n",
    "\n",
    "# 将文件名写入到 train.txt 文件中\n",
    "# with open(f'Dataset1.0/{whichset}.txt', 'w') as f:\n",
    "with open(f'Dataset1.0/train.txt', 'w') as f:\n",
    "    for file_name in file_names:\n",
    "        f.write(os.path.splitext(file_name)[0] + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes is  ['car', 'truck']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from utils.utils import get_classes\n",
    "\n",
    "classes_path        = 'model_data/vehicle_classes.txt'\n",
    "classes, _          = get_classes(classes_path)\n",
    "print(\"classes is \", classes)\n",
    "whichpath           = \"Dataset1.0\"\n",
    "nums                = np.zeros(len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Image file Dataset1.0/images/C006_labels.jpg does not exist. Skipping.\n",
      "Conversion complete. Output saved to Dataset1.0/train.txt\n",
      "Dataset split complete:\n",
      "  Training data: 8556 samples\n",
      "  Validation data: 1426 samples\n",
      "  Test data: 4278 samples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "def convert_yolo_to_custom_format(label_dir, image_dir, output_file, image_extension=\".jpg\", image_width=1280, image_height=720):\n",
    "    \"\"\"\n",
    "    Converts YOLO format labels to custom format for train.txt.\n",
    "    \n",
    "    Args:\n",
    "        label_dir (str): Path to the directory containing label files (.txt).\n",
    "        image_dir (str): Path to the directory containing image files.\n",
    "        output_file (str): Path to save the combined file.\n",
    "        image_extension (str): Extension of image files, e.g., '.jpg'.\n",
    "        image_width (int): Width of the image in pixels.\n",
    "        image_height (int): Height of the image in pixels.\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        for label_file in sorted(os.listdir(label_dir)):\n",
    "            if label_file.endswith(\".txt\"):\n",
    "                # Determine the corresponding image file\n",
    "                base_name = os.path.splitext(label_file)[0]\n",
    "                image_path = os.path.join(image_dir, f\"{base_name}{image_extension}\")\n",
    "                \n",
    "                # Ensure the image file exists\n",
    "                if not os.path.exists(image_path):\n",
    "                    print(f\"Warning: Image file {image_path} does not exist. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Start writing the line with the image path\n",
    "                outfile.write(image_path)\n",
    "                \n",
    "                # Read the label file\n",
    "                label_path = os.path.join(label_dir, label_file)\n",
    "                with open(label_path, 'r') as infile:\n",
    "                    for line in infile:\n",
    "                        class_id, center_x, center_y, width, height = map(float, line.split())\n",
    "                        \n",
    "                        # Convert YOLO normalized coordinates to pixel coordinates\n",
    "                        x_min = int((center_x - width / 2) * image_width)\n",
    "                        y_min = int((center_y - height / 2) * image_height)\n",
    "                        x_max = int((center_x + width / 2) * image_width)\n",
    "                        y_max = int((center_y + height / 2) * image_height)\n",
    "                        \n",
    "                        # Append the bounding box and class info\n",
    "                        outfile.write(f\" {x_min},{y_min},{x_max},{y_max},{int(class_id)}\")\n",
    "                \n",
    "                # End the line\n",
    "                outfile.write(\"\\n\")\n",
    "    print(f\"Conversion complete. Output saved to {output_file}\")\n",
    "\n",
    "def split_dataset(input_file, train_file, val_file, test_file, train_ratio=0.6, val_ratio=0.1, test_ratio=0.3):\n",
    "    \"\"\"\n",
    "    Splits a dataset file into train, val, and test files based on given ratios.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to the combined dataset file.\n",
    "        train_file (str): Path to save the training dataset.\n",
    "        val_file (str): Path to save the validation dataset.\n",
    "        test_file (str): Path to save the test dataset.\n",
    "        train_ratio (float): Ratio of training data.\n",
    "        val_ratio (float): Ratio of validation data.\n",
    "        test_ratio (float): Ratio of test data.\n",
    "    \"\"\"\n",
    "    with open(input_file, 'r') as infile:\n",
    "        lines = infile.readlines()\n",
    "    \n",
    "    # Shuffle the data for random splitting\n",
    "    random.shuffle(lines)\n",
    "    \n",
    "    # Calculate split indices\n",
    "    total = len(lines)\n",
    "    train_end = int(total * train_ratio)\n",
    "    val_end = train_end + int(total * val_ratio)\n",
    "    \n",
    "    # Split the dataset\n",
    "    train_data = lines[:train_end]\n",
    "    val_data = lines[train_end:val_end]\n",
    "    test_data = lines[val_end:]\n",
    "    \n",
    "    # Write to respective files\n",
    "    with open(train_file, 'w') as train_out:\n",
    "        train_out.writelines(train_data)\n",
    "    \n",
    "    with open(val_file, 'w') as val_out:\n",
    "        val_out.writelines(val_data)\n",
    "    \n",
    "    with open(test_file, 'w') as test_out:\n",
    "        test_out.writelines(test_data)\n",
    "    \n",
    "    print(f\"Dataset split complete:\")\n",
    "    print(f\"  Training data: {len(train_data)} samples\")\n",
    "    print(f\"  Validation data: {len(val_data)} samples\")\n",
    "    print(f\"  Test data: {len(test_data)} samples\")\n",
    "\n",
    "# Example usage\n",
    "label_dir = \"Dataset1.0/labels\"\n",
    "image_dir = \"Dataset1.0/images\"\n",
    "output_file = \"Dataset1.0/train.txt\"\n",
    "train_file = \"Dataset1.0/train_split.txt\"\n",
    "val_file = \"Dataset1.0/val_split.txt\"\n",
    "test_file = \"Dataset1.0/test_split.txt\"\n",
    "image_width = 1920  # Replace with actual image width\n",
    "image_height = 1080  # Replace with actual image height\n",
    "\n",
    "# Convert YOLO labels to custom format\n",
    "convert_yolo_to_custom_format(label_dir, image_dir, output_file, image_extension=\".jpg\", image_width=image_width, image_height=image_height)\n",
    "\n",
    "# Split the dataset into train, val, and test sets\n",
    "split_dataset(output_file, train_file, val_file, test_file, train_ratio=0.6, val_ratio=0.1, test_ratio=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is not used by 11/25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_annotation(image_id, list_file, image_set):\n",
    "    \n",
    "\n",
    "    in_file = open(os.path.join(f'{whichpath}/%slabel/%s.xml'%(image_set, image_id)), encoding='utf-8')\n",
    "\n",
    "\n",
    "    tree=ET.parse(in_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "\n",
    "    for obj in root.iter('object'):\n",
    "\n",
    "        difficult = 0 \n",
    "        if obj.find('difficult')!=None:\n",
    "            difficult = obj.find('difficult').text\n",
    "\n",
    "        cls = obj.find('name').text\n",
    "        if  int(difficult)==1 or cls not in classes:\n",
    "            continue\n",
    "        cls_id = classes.index(cls)\n",
    "        xmlbox = obj.find('bndbox')\n",
    "        b = (int(float(xmlbox.find('xmin').text)), int(float(xmlbox.find('ymin').text)), int(float(xmlbox.find('xmax').text)), int(float(xmlbox.find('ymax').text)))\n",
    "        list_file.write(\" \" + \",\".join([str(a) for a in b]) + ',' + str(cls_id))\n",
    "        \n",
    "        nums[classes.index(cls)] = nums[classes.index(cls)] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| bsu | 344 | \n",
      "| ecl | 954 | \n",
      "|  lm | 759 | \n"
     ]
    }
   ],
   "source": [
    "\n",
    "random.seed(0)\n",
    "Sets = [('train'),('val'),('test')]\n",
    "\n",
    "\n",
    "type_index = 0\n",
    "for image_set in Sets:\n",
    "    image_ids = open(os.path.join(f'{whichpath}/%s.txt'%(image_set)), encoding='utf-8').read().strip().split()\n",
    "    list_file = open(f'{whichpath}/%slabel.txt'%(image_set), 'w', encoding='utf-8')\n",
    "    for image_id in image_ids:\n",
    "        list_file.write(f'{whichpath}/%s/%s.jpg'%(image_set, image_id))\n",
    "\n",
    "        convert_annotation(image_id, list_file, image_set)\n",
    "        list_file.write('\\n')\n",
    "    type_index += 1\n",
    "    list_file.close()\n",
    "\n",
    "\n",
    "def printTable(List1, List2):\n",
    "    for i in range(len(List1[0])):\n",
    "        print(\"|\", end=' ')\n",
    "        for j in range(len(List1)):\n",
    "            print(List1[j][i].rjust(int(List2[j])), end=' ')\n",
    "            print(\"|\", end=' ')\n",
    "        print()\n",
    "\n",
    "str_nums = [str(int(x)) for x in nums]\n",
    "tableData = [\n",
    "    classes, str_nums\n",
    "]\n",
    "colWidths = [0]*len(tableData)\n",
    "len1 = 0\n",
    "for i in range(len(tableData)):\n",
    "    for j in range(len(tableData[i])):\n",
    "        if len(tableData[i][j]) > colWidths[i]:\n",
    "            colWidths[i] = len(tableData[i][j])\n",
    "printTable(tableData, colWidths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLOv7Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
